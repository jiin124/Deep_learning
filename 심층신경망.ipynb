{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "심층신경망",
      "provenance": [],
      "authorship_tag": "ABX9TyOVHGWDw2LYK5/FFNWOSPCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiin124/Deep_learning/blob/main/%EC%8B%AC%EC%B8%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 신경망\n",
        "\n"
      ],
      "metadata": {
        "id": "thFZzhldZpor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXvhGbRGRyST",
        "outputId": "70489814-6c90-41de-93e3-09a5791e4bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "(train_input,train_target),(test_input,test_target)=keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지의 픽셀값을 0~255 범위에서 0~1사이로 변화하고 28*28 크기의 2차원 배열을 784 크기의 1차원 배열로 펼친다. "
      ],
      "metadata": {
        "id": "w4H3WRlpaNwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled=train_input/255.0\n",
        "train_scaled=train_scaled.reshape(-1,28*28)\n",
        "train_scaled,val_scaled,train_target,val_target=train_test_split(train_scaled,train_target,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "k8A5KqhfZ4PA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 인공 신경망 모델에 층을 2개 추가해보겠다. \n",
        "\n",
        "입력층과 출력층 사이에 있는 모든 층을 은닉층이라고 한다. \n",
        "은닉층에는 활성화 함수가 표시되어있는데 활성화 함수는 신경망 층의 선형 방정식의 계산 값에 사용하는 값이다. 이전에 출력층에 적용했던 소프트맥스 함수도 활성화함수이다. 출려긍에 적용하는 활성화 함수는 종류가 제한되어있다. 이진분류일경우 시그모이드 함수를 사용하고 다중 분류일 경우 소프트 맥스 함수를 사용한다. 이에 비해 은닉층의 활성화 함수는 비교적 자유롭다. 대표적으로 시그모이드 함수와 렐루 함수를 사용한다.\n",
        "\n",
        "- 회귀를 위한 신경망의 출력층에서는 어떤 활성화 함수를 사용할까?\n",
        "분류문제는 클래스에 대한 확률을 출력하기 위해 활성화 함수를 사용한다. 회귀의 출력은 임의의 어떤 숫자이므로 활성화 함수를 적용할 필요가 없다. 출력층의 선형 방정식의 계산을 그대로 출력한다. 이렇게 하려면 Dense 층의 activation 매개변수에 아무런 값을 지정하지 않는다. \n",
        "\n",
        "- 은닉층에 활성화 함수를 사용하는 이유\n",
        "\n",
        "은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없다. 선형 계산을 적당하게 비선형적으로 비틀어주어야 한다. 그래야 다음 층의 꼐산과 단순히 합쳐지지 않고 나름의 역할을 할 수 있다. \n"
      ],
      "metadata": {
        "id": "k2V7cSn3azxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1=keras.layers.Dense(100,activation='sigmoid',input_shape=(784,))\n",
        "dense2=keras.layers.Dense(10,activation='softmax')"
      ],
      "metadata": {
        "id": "WOhgHxfZaq61"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dense1이 은닉층이고 100개의 뉴런을 가진 밀집층이다 활성화 함수를 시그모이드로 지정했고 input_shape에서 입력의 크기를 (784,)로 지정했다. 은닉층의 뉴런 개수를 정하는데는 특별한 기준이 없다. 몇 개의 뉴런을 두어야 할지 판단하기 위해서는 상당한 경험이 필요하다. \n",
        "\n",
        "\n",
        "여기서 한가지 제약 사항이 있다면 적어도 출력층의 뉴런보다는 많게 만들어야 한다. 클래스 10개에 대한 확률을 예측해야하는데 이전 은닉층이 10개보다 적다면 부족한 정보가 전달될 것이다. \n",
        "\n",
        "그다음은 dense2는 출력층이다. 10개의 클래스를 분류하므로, 10개의 뉴런을 두었고 활성화 함수는 소프트 맥스 함수로 지정했다. "
      ],
      "metadata": {
        "id": "BG6ePWBhgFoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층 신경망 만들기\n",
        "\n",
        "앞에서 만든 dense1,dense2 객체를 Sequential 클래스에 추가해 심층 신경망(Deep neural network DNN)을 만들어보겠다. "
      ],
      "metadata": {
        "id": "Np8ZvwSzggsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential([dense1,dense2])"
      ],
      "metadata": {
        "id": "Q84LGo-OgEjs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential 클래스의 객체를 만들 때 여러개의 층을 추가하려면 리스트로 만들어 전달해야한다. 여기서 주의할 것은 출력층을 가장 마지막에 두어야 한다는 것. \n",
        "\n",
        "인공 신경망의 강력한 성능은 바로 이렇게 층을 추가해 입력 데이터에 대해 연속적인 학습을 진행하는 능력에서 나온다. "
      ],
      "metadata": {
        "id": "y-j4-jvVgvfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYZGyLcCguFo",
        "outputId": "3de817fd-0234-4115-a74f-049414145da0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "맨 첫줄에 모델의 이름이 나온다 그다음 이 모델에 들어있는 층이 순서대로 나열된다 이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서대로 나열된다 .층마다 층 이름, 클래스, 출력크기, 모델 파라미터 개수가 출련된다 층을 만들 떄 name 매개변수로 이름을 지정할 수 있다. 층 이름을 지정하지 않으면 케라스가 자동으로 dense라고 이름을 붙인다. \n",
        "\n",
        "출력의 크기를 보면 (None, 100)이다. 첫번째 차언은 샘플의 개수를 나타낸다. 샘플 개수가 아직 정의되어있지 않기 때문에 None이다. 왤까? 케라스 모델의 fit()메서드에 훈련데이터를 주입하면 이 데이터를 한번에 모두 사용하지 않고 잘게 나누어 여러번에 걸쳐 경사 하강법 단계를 수행한다. 바로 미니배치 경사 하강법을 사용하는 것이다. \n",
        "\n",
        "케라스의 기본 미니 배치 크기는 32개이다. 이 값은 fit()메서드에서 batch_size 매개변수로 바꿀 수 있다. 따라서 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다. 이렇게 신경망 층에 입력되거나 출력되는 배열의 첫번째 차원을 배치 차원이라고 부른다. \n",
        "\n",
        "두번째 100은 쉽다. 은닉층의 뉴런개수를 100개로 두었으니 100개의 출력이 나온다. 즉 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축되었다. \n",
        "\n",
        "마지막으로 모델 파라미터 개수가 출력된다. 이 층은 Dense 층이므로 입력 픽셀 784개와 100개의 모든 조합에 대한 가중치가 있다. 그리고 뉴런마다 1개의 절편이 있따.\n",
        "784*100+100=78500\n",
        "\n",
        "두번째 층의 출력크기는 (None,10)이다. 배치차원은 동일하게 None이고 출력 뉴런 개수가 10개이기 때문이다. 이 층의 모델 파라미터 개수는\n",
        "10*100+10=1010\n",
        "\n",
        "summary() 메서드의 마지막에는 총 모델 파라미터 개수와 훈련되는 파라미터 개수가 동일하게 79510개로 나온다. 은닉층과 출력층의 파라미터 개수를 합친 값이다. "
      ],
      "metadata": {
        "id": "tAwXZBmthqZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 층을 추가하는 다른 방법\n",
        "\n",
        "sequential 클래스에 층을 추가하는 다른 방법을 알아보자, 앞에서는 Dense 클래스의 객체 dense1,dense2를 만들어 sequential 클래스에 전달했다. 이 두 객체를 따로 저장해 쓸일이 없기 때문에 다음 처럼 sequential 클래스의 생성자 안에서 바로 dense 클래스의 객체를 만드는 경우가 많다."
      ],
      "metadata": {
        "id": "fa3KEDXDyiBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential([\n",
        "                        keras.layers.Dense(100,activation='sigmoid',input_shape=(784,),\n",
        "                                           name='hidden'),\n",
        "                        keras.layers.Dense(10,activation='softmax',name='output')\n",
        "],name='패션 MNIST모델')"
      ],
      "metadata": {
        "id": "zP01jR_AhAa2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 작업하면 추가되는 층을 한눈에 쉽게 알아보는 장점이 있다 이전과는 달리 이번에는 sequential 클래스의 name 매개변수로 모델의 이름을 정했다. 또 Dense 층의 name 매개변수에 층의 이름을 'hidden'과 'output'으로 각각 지정했다. "
      ],
      "metadata": {
        "id": "oPJ7DBcnzner"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QHS4goXzd_e",
        "outputId": "05287ef0-5477-45b7-ea72-8631bbe7c2c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 모델과 많은 층을 사용할 때 name 매개변수를 사용하면 구분하기 쉽다. 이 방법이 편리하지만 아주 많은 층을 추가하려면 sequential 클래스 생성자가 매우 길어진다. 또 조건에 따라 층을 추가할 수도 없다. Sequential 클래스에서 층을 추가할 떄 가장 널리 사용하는 방법은 add() 메서드이다. "
      ],
      "metadata": {
        "id": "3-twfv3c0Ic1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential()\n",
        "model.add(keras.layers.Dense(100,activation='sigmoid',input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "_6d8yrSp0FwW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPaOs1PU0itK",
        "outputId": "3b4474fe-626b-4e98-8319-ba3fb0514460"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 모델을 훈련해보자 compile() 메서드의 설정은 1절에서 했던 것과 동일하다. 5번의 에포크동안 훈련해보자. "
      ],
      "metadata": {
        "id": "p8VPLEBZ00A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
        "model.fit(train_scaled,train_target,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRdLfyhq0xhR",
        "outputId": "d8f0991b-a25f-4bb5-fedc-095034a4a2fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5638 - accuracy: 0.8097\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4063 - accuracy: 0.8538\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3724 - accuracy: 0.8668\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3493 - accuracy: 0.8748\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3314 - accuracy: 0.8800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f21864150>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가된 층이 성능을 향상시킨 것을 알 수 있다. "
      ],
      "metadata": {
        "id": "DYM_3GrX1V71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 렐루 함수\n",
        "\n",
        "초창기 인공 신경망의 은닉층에 많이 사용된 활성화 함수는 시그모이드 함수이다. 하지만 이 함수에는 단점이 있다. 이 함수의 오른쪽과 왼쪽 끝으로 갈수로 그래프가 누워있기 떄문에 올바른 출력을 만드는데 신속하게 대응하지 못한다. "
      ],
      "metadata": {
        "id": "82VnLEaK1an1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "wMwHbqDU1Evz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫번째 Dense층에 있던 input_shape 매개변수를 flatten 층으로 옮겼다. 또 첫번째 dense 층의 활성화 함수를 relu로 바꾸었다. 하지만 이 신경망을 깊이가 3인 신경망이라고 부르진 않는다.flatten 클래스는 학습하는 층이 아니기 때문이다. "
      ],
      "metadata": {
        "id": "Yq4X6bLj_Ksr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOmkrB51-Jjh",
        "outputId": "59fcb954-9e1e-4879-ac46-ceea5c6b7ad0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "flatten클래스에 포함된 모델 파라미터는 0개이다. 케라스의 flatten 층을 신경망 모델에 추가하면 입력값의 차원을 짐작할 수 있는 것이 또하나의 장점이다. 임력데이터에 대한 전처리과정을 가능한 모델에 포함시키는 것이 케라스 aPi의 철학 중 하나이다. "
      ],
      "metadata": {
        "id": "mmbilJDe_lsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input,train_target),(test_input,test_target)=keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled=train_input/255.0\n",
        "train_scaled,val_scaled,train_target,val_target=train_test_split(train_scaled,train_target,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "f7CclB-C_ZPZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',metrics='accuracy')\n",
        "model.fit(train_scaled,train_target,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiI34GQ6AWLc",
        "outputId": "fd67aacf-755e-4f9f-babd-dc936e24fa4a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5354 - accuracy: 0.8108\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3969 - accuracy: 0.8575\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3580 - accuracy: 0.8709\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3357 - accuracy: 0.8791\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3245 - accuracy: 0.8845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f21c2da10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "음, 크지는 않지만 렐루 함수의 효과를 본것 같다. 이제 검증 세트에서의 성능도 확인 ㄱ"
      ],
      "metadata": {
        "id": "6SD93iM9ByPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ettq6VAVAs0g",
        "outputId": "f0b45650-86bd-4891-c022-cc88f964d2da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37034687399864197, 0.8744999766349792]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',\n",
        "              metrics='accuracy')"
      ],
      "metadata": {
        "id": "fnlxvggqCar1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd=keras.optimizers.SGD()\n",
        "model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics='accuracy')"
      ],
      "metadata": {
        "id": "W0kKnYXJFCyk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd=keras.optimizers.SGD(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "QfkhSwk3FtYp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adagrad=keras.optimizers.Adagrad()\n",
        "model.compile(optimizer=adagrad,loss='sparse_categorical_crossentropy',\n",
        "              metrics='accuracy')"
      ],
      "metadata": {
        "id": "gavwY0CoGHVN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop=keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=rmsprop,loss='sparse_cagegorical_crossentropy',metrics='accuracy')"
      ],
      "metadata": {
        "id": "VRJnmTcwLZu6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "LJXpUvMDL7Cy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
        "              metrics='accuracy')\n",
        "model.fit(train_scaled,train_target,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ix8dPeOifZ",
        "outputId": "da4c8736-c01b-4969-94b9-d693f259f8e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5207 - accuracy: 0.8179\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3922 - accuracy: 0.8597\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3500 - accuracy: 0.8722\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3245 - accuracy: 0.8815\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3041 - accuracy: 0.8884\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2f2157fe90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbLPmnPoPxUR",
        "outputId": "2157fd72-de90-44aa-beaa-fc866ae8c8af"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3301205337047577, 0.8822500109672546]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eXWjOA5XQKDJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}